{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Translation\n",
    "\n",
    "`Task:`\n",
    "- Develop a model that can translate a Tamil input sentence to English. \n",
    "- Analyze the impact of various embedding techniques in the translation task. \n",
    "- Use  sequence  model  to  translate  the  Tamil  input  sentence  and  analyze  the  performance  of various techniques. \n",
    "- Translate the input sentences using Transformer model and understand its functioning.  \n",
    "- Translate the following Tamil Phrase and evaluate your model based on the expected output.  \n",
    "    - Input 1: நான் மிகவும் சந்த ாஷமாக இருக்கிதேன்  \n",
    "    - Expected Output: Im so happy  \n",
    "    - Input 2: அது அவசியமில்லை \n",
    "    - Expected Output: It wasnt necessary \n",
    "    - Input 3:  யவுசசய்து அல  மீண்டும் சசய்யவும் \n",
    "    - Expected Output: Please do that again \n",
    "    - Input 4: அது ஒரு நல்ை தயாசலை \n",
    "    - Expected Output: That is a good idea \n",
    "    - Input 5: அவர்கள் ஒன்ோக தவலை சசய்ய ஒப்புக்சகாண்டைர் \n",
    "    - Expected Output: They agreed to work together "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import LSTM,Embedding,RepeatVector,Dense,Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_path = 'Dataset/data.en'\n",
    "ta_path = 'Dataset/data.ta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentences, ta_sentences = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,7):\n",
    "    en_sentences.extend(read_sentences(en_path + str(i)))\n",
    "    ta_sentences.extend(read_sentences(ta_path + str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['moreover all the vessels , which king ahaz in his reign did cast away in his transgression , have we prepared and sanctified , and , behold , they are before the altar of the lord .',\n",
       "  'similar conditions will be imposed if the sri lankan government is given an imf loan .'],\n",
       " ['ராஜாவாகிய ஆகாஸ் அரசாளும்போது தம்முடைய பாதகத்தினால் எறிந்துபோட்ட சகல பணிமுட்டுகளையும் முஸ்திப்பாக்கிப் பரிசுத்தம்பண்ணினோம்; இதோ , அவைகள் கர்த்தரின் ஆலயத்திற்கு முன்பாக இருக்கிறது என்றார்கள் .',\n",
       "  'சர்வதேச நாணய நிதியம் இலங்கைக்கு கடன் வழங்கினால் இதே போன்ற நிபந்தனைகள் திணிக்கப்படும் .'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sentences[:2], ta_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289456, 289456)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_sentences), len(ta_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tam.txt','r',encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I slept.\\tநான் தூங்கினேன்.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3199633 (CM) & #7098307 (Singaravelu)',\n",
       " 'Calm down.\\tஅமைதியாக இருங்கள்\\tCC-BY 2.0 (France) Attribution: tatoeba.org #435575 (CK) & #4268041 (Singaravelu)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I slept.',\n",
       " 'நான் தூங்கினேன்.',\n",
       " 'CC-BY 2.0 (France) Attribution: tatoeba.org #3199633 (CM) & #7098307 (Singaravelu)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines[:-1]:\n",
    "    en_sent, ta_sent, _ = line.split('\\t')\n",
    "    en_sentences.append(en_sent)\n",
    "    ta_sentences.append(ta_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289657, 289657)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_sentences), len(ta_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only the first 10000 sentences\n",
    "en_sentences = en_sentences[:10000]\n",
    "ta_sentences = ta_sentences[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences =['START_ '+sent.lower().translate(str.maketrans('','',string.punctuation))+' _END' for sent in en_sentences] # for each sentence add start and end token, lower case and remove punctuation - str.maketrans() method is creating a translation table that maps every punctuation character to None\n",
    "tamil_sentences =[sent.translate(str.maketrans('','',string.punctuation))for sent in ta_sentences] # remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('START_ moreover all the vessels  which king ahaz in his reign did cast away in his transgression  have we prepared and sanctified  and  behold  they are before the altar of the lord  _END',\n",
       " 'ராஜாவாகிய ஆகாஸ் அரசாளும்போது தம்முடைய பாதகத்தினால் எறிந்துபோட்ட சகல பணிமுட்டுகளையும் முஸ்திப்பாக்கிப் பரிசுத்தம்பண்ணினோம் இதோ  அவைகள் கர்த்தரின் ஆலயத்திற்கு முன்பாக இருக்கிறது என்றார்கள் ')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[0], tamil_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>tamil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>START_ moreover all the vessels  which king ah...</td>\n",
       "      <td>ராஜாவாகிய ஆகாஸ் அரசாளும்போது தம்முடைய பாதகத்தி...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>START_ similar conditions will be imposed if t...</td>\n",
       "      <td>சர்வதேச நாணய நிதியம் இலங்கைக்கு கடன் வழங்கினால...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>START_ now kornelius argues the opposite inste...</td>\n",
       "      <td>தற்போது அதற்கு எதிராக வாதாடுகிறார் சர்வதேச சட...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>START_ chrysler the third largest us automaker...</td>\n",
       "      <td>அமெரிக்காவின் மூன்றாம் பெரிய கார் தயாரிப்பு நி...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>START_ moreover  khan has been in exile in ira...</td>\n",
       "      <td>மேலும் இனைவிட்டு தலிபானால் வெளியேற்றப்பட்ட 199...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  START_ moreover all the vessels  which king ah...   \n",
       "1  START_ similar conditions will be imposed if t...   \n",
       "2  START_ now kornelius argues the opposite inste...   \n",
       "3  START_ chrysler the third largest us automaker...   \n",
       "4  START_ moreover  khan has been in exile in ira...   \n",
       "\n",
       "                                               tamil  \n",
       "0  ராஜாவாகிய ஆகாஸ் அரசாளும்போது தம்முடைய பாதகத்தி...  \n",
       "1  சர்வதேச நாணய நிதியம் இலங்கைக்கு கடன் வழங்கினால...  \n",
       "2  தற்போது அதற்கு எதிராக வாதாடுகிறார் சர்வதேச சட...  \n",
       "3  அமெரிக்காவின் மூன்றாம் பெரிய கார் தயாரிப்பு நி...  \n",
       "4  மேலும் இனைவிட்டு தலிபானால் வெளியேற்றப்பட்ட 199...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.DataFrame({'english':english_sentences,'tamil':tamil_sentences})\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sentence by space and count the number of words\n",
    "lines['length_en_sent'] = lines['english'].apply(lambda x:len(x.split(\" \"))) \n",
    "lines['length_ta_sent'] = lines['tamil'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>tamil</th>\n",
       "      <th>length_en_sent</th>\n",
       "      <th>length_ta_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>START_ moreover all the vessels  which king ah...</td>\n",
       "      <td>ராஜாவாகிய ஆகாஸ் அரசாளும்போது தம்முடைய பாதகத்தி...</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>START_ similar conditions will be imposed if t...</td>\n",
       "      <td>சர்வதேச நாணய நிதியம் இலங்கைக்கு கடன் வழங்கினால...</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>START_ now kornelius argues the opposite inste...</td>\n",
       "      <td>தற்போது அதற்கு எதிராக வாதாடுகிறார் சர்வதேச சட...</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>START_ chrysler the third largest us automaker...</td>\n",
       "      <td>அமெரிக்காவின் மூன்றாம் பெரிய கார் தயாரிப்பு நி...</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>START_ moreover  khan has been in exile in ira...</td>\n",
       "      <td>மேலும் இனைவிட்டு தலிபானால் வெளியேற்றப்பட்ட 199...</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  START_ moreover all the vessels  which king ah...   \n",
       "1  START_ similar conditions will be imposed if t...   \n",
       "2  START_ now kornelius argues the opposite inste...   \n",
       "3  START_ chrysler the third largest us automaker...   \n",
       "4  START_ moreover  khan has been in exile in ira...   \n",
       "\n",
       "                                               tamil  length_en_sent  \\\n",
       "0  ராஜாவாகிய ஆகாஸ் அரசாளும்போது தம்முடைய பாதகத்தி...              39   \n",
       "1  சர்வதேச நாணய நிதியம் இலங்கைக்கு கடன் வழங்கினால...              18   \n",
       "2  தற்போது அதற்கு எதிராக வாதாடுகிறார் சர்வதேச சட...              27   \n",
       "3  அமெரிக்காவின் மூன்றாம் பெரிய கார் தயாரிப்பு நி...              33   \n",
       "4  மேலும் இனைவிட்டு தலிபானால் வெளியேற்றப்பட்ட 199...              28   \n",
       "\n",
       "   length_ta_sent  \n",
       "0              19  \n",
       "1              11  \n",
       "2              16  \n",
       "3              29  \n",
       "4              11  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only those sentences with words less than 50\n",
    "lines = lines[lines['length_en_sent']<=50]\n",
    "lines = lines[lines['length_ta_sent']<=50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9727, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START_ moreover all the vessels  which king ahaz in his reign did cast away in his transgression  have we prepared and sanctified  and  behold  they are before the altar of the lord  _END'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18682, 46735)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_corpus = set()\n",
    "ta_corpus = set()   \n",
    "\n",
    "for sent in english_sentences:\n",
    "    for word in sent.split():\n",
    "        if word not in en_corpus: en_corpus.add(word)\n",
    "        \n",
    "for sent in tamil_sentences:\n",
    "    for word in sent.split():\n",
    "        if word not in ta_corpus: ta_corpus.add(word)\n",
    "        \n",
    "len(en_corpus), len(ta_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_corpus = sorted(list(en_corpus))\n",
    "ta_corpus = sorted(list(ta_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(ta_corpus)\n",
    "num_decoder_tokens = len(en_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46735, 18682)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 # for zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word,i+1) for i,word in enumerate(en_corpus)])\n",
    "target_token_index = dict([(word,i+1) for i,word in enumerate(ta_corpus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(lines['tamil'],lines['english'],test_size = 0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_pickle('x_train.pkl') \n",
    "x_test.to_pickle('x_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
